% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/llm_setup.R
\name{llm_pull_model}
\alias{llm_pull_model}
\title{Pull (download) a vision model from Ollama}
\usage{
llm_pull_model(model = "qwen2.5vl:7b", base_url = "http://localhost:11434")
}
\arguments{
\item{model}{Model name to download. Default \code{"qwen2.5vl:7b"}.}

\item{base_url}{Base URL for Ollama server. Default \code{"http://localhost:11434"}.}
}
\value{
TRUE if successful, FALSE otherwise.
}
\description{
Downloads a vision-capable model for use with tidylens LLM functions.
}
\details{
\subsection{Model Size Guide}{\tabular{llll}{
   Model \tab Size (RAM needed) \tab Speed \tab Quality \cr
   moondream \tab ~2GB \tab Very Fast \tab Good \cr
   qwen2.5vl:3b \tab ~3GB \tab Fast \tab Good \cr
   qwen2.5vl:7b \tab ~5GB \tab Medium \tab Excellent \cr
   llava:7b \tab ~5GB \tab Medium \tab Very Good \cr
   qwen2.5vl:32b \tab ~20GB \tab Slow \tab Superior \cr
}

}

\subsection{Recommendations by Hardware}{
\itemize{
\item \strong{8GB RAM}: moondream, qwen2.5vl:3b.
\item \strong{16GB RAM}: qwen2.5vl:7b, llava:7b.
\item \strong{32GB+ RAM}: qwen2.5vl:32b, llama3.2-vision:11b.
}
}
}
\examples{
\dontrun{
llm_pull_model("moondream")
llm_pull_model("qwen2.5vl:7b")
llm_pull_model("llama3.2-vision")
}

}
\seealso{
Other llm: 
\code{\link{llm_check_dependencies}()},
\code{\link{llm_check_ollama}()},
\code{\link{llm_classify}()},
\code{\link{llm_describe}()},
\code{\link{llm_list_models}()},
\code{\link{llm_recognize}()},
\code{\link{llm_sentiment}()},
\code{\link{llm_setup_instructions}()}
}
\concept{llm}
