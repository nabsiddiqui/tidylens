% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/llm_setup.R
\name{llm_list_models}
\alias{llm_list_models}
\title{List available vision models from Ollama}
\usage{
llm_list_models(base_url = "http://localhost:11434", only_installed = FALSE)
}
\arguments{
\item{base_url}{Base URL for Ollama server. Default \code{"http://localhost:11434"}.}

\item{only_installed}{If TRUE, only show installed models. Default FALSE.}
}
\value{
A tibble with model information, or NULL if Ollama is not running.
}
\description{
Lists vision-capable models that can be used with tinylens LLM functions.
}
\details{
\subsection{Recommended Vision Models}{\tabular{lll}{
   Model \tab Size \tab Description \cr
   qwen2.5vl \tab 3-72B \tab Best overall vision model for captioning \cr
   qwen3-vl \tab 2-235B \tab Latest Qwen vision model \cr
   llama3.2-vision \tab 11-90B \tab Meta's vision model \cr
   llava \tab 7-34B \tab Classic vision-language model \cr
   minicpm-v \tab 8B \tab Efficient multimodal model \cr
   moondream \tab 1.8B \tab Small, fast, edge-optimized \cr
   gemma3 \tab 1-27B \tab Google's vision model \cr
}


For film/humanities research, we recommend:
\itemize{
\item \strong{qwen2.5vl:7b} - Best balance of quality and speed.
\item \strong{moondream} - Fast processing for large batches.
\item \strong{llama3.2-vision} - Good general-purpose alternative.
}
}
}
\examples{
\dontrun{
llm_list_models()
llm_list_models(only_installed = TRUE)
}

}
\seealso{
Other llm: 
\code{\link{llm_check_dependencies}()},
\code{\link{llm_check_ollama}()},
\code{\link{llm_classify}()},
\code{\link{llm_describe}()},
\code{\link{llm_pull_model}()},
\code{\link{llm_recognize}()},
\code{\link{llm_sentiment}()},
\code{\link{llm_setup_instructions}()}
}
\concept{llm}
